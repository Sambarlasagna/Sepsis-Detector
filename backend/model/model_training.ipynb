{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce23a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Dataset Definition\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Dataset wrapper for sequences\n",
    "class SepsisDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        print(f\"Dataset created with {len(self.X)} samples, each of shape {self.X.shape[1:]}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b7274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: GRU Regression Model\n",
    "class GRUTimeToSepsis(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1):\n",
    "        super(GRUTimeToSepsis, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)  # shape: (batch, seq_len, hidden_size)\n",
    "        out = out[:, -1, :]   # last timestep\n",
    "        out = self.fc(out)    # shape: (batch, 1)\n",
    "        return out.squeeze(1) # flatten to (batch,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e6c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataframe shape: (1552210, 44)\n",
      "   Hour        HR     O2Sat      Temp       SBP       MAP       DBP      Resp  \\\n",
      "0     0  0.726119 -0.693117 -1.039536 -1.107301 -0.449908 -0.138132  0.066447   \n",
      "1     1  0.726119 -0.693117 -1.039536 -1.107301 -0.449908 -0.138132  0.066447   \n",
      "2     2  0.266199  0.592670 -1.039536 -0.073710  0.200366 -0.138132  0.647755   \n",
      "3     3  0.323689 -0.693117 -1.039536 -0.073710  0.200366 -0.138132  2.197910   \n",
      "4     4  1.071059 -2.782520 -1.039536 -0.073710  0.525199 -0.138132  1.132179   \n",
      "\n",
      "      EtCO2  BaseExcess  ...  Platelets       Age   Gender     Unit1  \\\n",
      "0 -0.019219    9.617977  ...   1.101793  1.289531 -1.12648 -0.655897   \n",
      "1 -0.019219    9.617977  ...   1.101793  1.289531 -1.12648 -0.655897   \n",
      "2 -0.019219    9.617977  ...   1.101793  1.289531 -1.12648 -0.655897   \n",
      "3 -0.019219    9.617977  ...   1.101793  1.289531 -1.12648 -0.655897   \n",
      "4 -0.019219    9.617977  ...   1.101793  1.289531 -1.12648 -0.655897   \n",
      "\n",
      "      Unit2  HospAdmTime    ICULOS  SepsisLabel  Patient_ID  time_to_sepsis  \n",
      "0  0.655897     0.345717 -0.896212            0           1              24  \n",
      "1  0.655897     0.345717 -0.861736            0           1              24  \n",
      "2  0.655897     0.345717 -0.827259            0           1              24  \n",
      "3  0.655897     0.345717 -0.792783            0           1              24  \n",
      "4  0.655897     0.345717 -0.758307            0           1              24  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "Features used: ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC', 'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Preprocessed Data and Patient IDs\n",
    "# Load your preprocessed full dataset (make sure it contains 'Patient_ID' column)\n",
    "full_df = pd.read_csv('../data/processed_sepsis_dataset.csv')\n",
    "\n",
    "print(f\"Full dataframe shape: {full_df.shape}\")\n",
    "print(full_df.head())\n",
    "\n",
    "# Extract the list of features used for modeling\n",
    "exclude_cols = ['Patient_ID', 'Hour', 'SepsisLabel', 'time_to_sepsis']\n",
    "features = [col for col in full_df.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Features used: {features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ac6f87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train patients: 32268\n",
      "Number of test patients: 8068\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Patient-level Train/Test Split\n",
    "import numpy as np\n",
    "\n",
    "# Unique patients\n",
    "patient_ids = full_df['Patient_ID'].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(patient_ids)\n",
    "\n",
    "split_idx = int(len(patient_ids) * 0.8)  # 80% train, 20% test split\n",
    "train_patients = patient_ids[:split_idx]\n",
    "test_patients = patient_ids[split_idx:]\n",
    "\n",
    "print(f\"Number of train patients: {len(train_patients)}\")\n",
    "print(f\"Number of test patients: {len(test_patients)}\")\n",
    "\n",
    "# Split dataframe accordingly\n",
    "train_df = full_df[full_df['Patient_ID'].isin(train_patients)]\n",
    "test_df = full_df[full_df['Patient_ID'].isin(test_patients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c63566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 884728 sequences each of length 12.\n",
      "Created 225463 sequences each of length 12.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Sequence Creation Function (redefine if not already)\n",
    "def create_sequences(df, patient_col='Patient_ID', hour_col='Hour', feature_cols=None, seq_length=12):\n",
    "    if feature_cols is None:\n",
    "        feature_cols = [c for c in df.columns if c not in [patient_col, hour_col, 'SepsisLabel', 'time_to_sepsis']]\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    patients = df[patient_col].unique()\n",
    "    for patient in patients:\n",
    "        patient_data = df[df[patient_col] == patient].sort_values(hour_col)\n",
    "        features_array = patient_data[feature_cols].values\n",
    "        time_to_sepsis_array = patient_data['time_to_sepsis'].values\n",
    "        for start in range(len(patient_data) - seq_length + 1):\n",
    "            end = start + seq_length\n",
    "            seq_X = features_array[start:end]\n",
    "            seq_y = time_to_sepsis_array[end - 1]\n",
    "            sequences.append(seq_X)\n",
    "            labels.append(seq_y)\n",
    "    X = np.array(sequences)\n",
    "    y = np.array(labels)\n",
    "    print(f\"Created {len(X)} sequences each of length {seq_length}.\")\n",
    "    return X, y\n",
    "\n",
    "# Create sequences for train and test sets\n",
    "seq_length = 12\n",
    "X_train, y_train = create_sequences(train_df, feature_cols=features, seq_length=seq_length)\n",
    "X_test, y_test = create_sequences(test_df, feature_cols=features, seq_length=seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2fe0a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 884728 samples, each of shape torch.Size([12, 40])\n",
      "Dataset created with 225463 samples, each of shape torch.Size([12, 40])\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Prepare Dataloaders for Training and Testing\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = SepsisDataset(X_train, y_train)\n",
    "test_dataset = SepsisDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4dcde45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training and Evaluation Functions\n",
    "\n",
    "def train_model(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(dataloader):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "        if batch_idx % 10 == 0 or batch_idx == len(dataloader)-1:\n",
    "            print(f\"Batch {batch_idx+1}/{len(dataloader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(dataloader):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            total_loss += loss.item() * X_batch.size(0)\n",
    "            if batch_idx % 10 == 0 or batch_idx == len(dataloader)-1:\n",
    "                print(f\"Eval Batch {batch_idx+1}/{len(dataloader)} - Loss: {loss.item():.4f}\")\n",
    "    return total_loss / len(dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56bc49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Epoch 1/5\n",
      "Batch 1/6912 - Loss: 552.3064\n",
      "Batch 11/6912 - Loss: 539.0088\n",
      "Batch 21/6912 - Loss: 527.3292\n",
      "Batch 31/6912 - Loss: 467.8586\n",
      "Batch 41/6912 - Loss: 373.0977\n",
      "Batch 51/6912 - Loss: 304.3159\n",
      "Batch 61/6912 - Loss: 278.6742\n",
      "Batch 71/6912 - Loss: 242.8077\n",
      "Batch 81/6912 - Loss: 218.2467\n",
      "Batch 91/6912 - Loss: 189.0996\n",
      "Batch 101/6912 - Loss: 172.9069\n",
      "Batch 111/6912 - Loss: 160.2070\n",
      "Batch 121/6912 - Loss: 146.5423\n",
      "Batch 131/6912 - Loss: 133.5807\n",
      "Batch 141/6912 - Loss: 121.6431\n",
      "Batch 151/6912 - Loss: 109.1778\n",
      "Batch 161/6912 - Loss: 99.9287\n",
      "Batch 171/6912 - Loss: 92.1254\n",
      "Batch 181/6912 - Loss: 82.1348\n",
      "Batch 191/6912 - Loss: 74.9256\n",
      "Batch 201/6912 - Loss: 71.2886\n",
      "Batch 211/6912 - Loss: 63.9621\n",
      "Batch 221/6912 - Loss: 54.9045\n",
      "Batch 231/6912 - Loss: 48.9568\n",
      "Batch 241/6912 - Loss: 43.7858\n",
      "Batch 251/6912 - Loss: 45.7541\n",
      "Batch 261/6912 - Loss: 37.1774\n",
      "Batch 271/6912 - Loss: 34.9693\n",
      "Batch 281/6912 - Loss: 32.0364\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Initialize Model, Optimizer, Criterion and Train\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "model = GRUTimeToSepsis(input_size, hidden_size, num_layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch} - Train Loss: {train_loss:.4f}\")\n",
    "    val_loss = evaluate_model(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch} - Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"gru_time_to_sepsis.pth\")\n",
    "print(\"Saved model to gru_time_to_sepsis.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f13caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Testing – Evaluate on Test Set\n",
    "\n",
    "test_loss = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Final Test Loss (MSE): {test_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
